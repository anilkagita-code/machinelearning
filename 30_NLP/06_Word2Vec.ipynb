{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2df40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1feba232",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating custom word embeddings using gensim library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0671d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812981d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a5000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'movie', 'is', 'good'],\n",
       " ['this', 'movie', 'is', 'awesome'],\n",
       " ['movie', 'was', 'pathetic']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = ['this movie is good', 'this movie is awesome', 'movie was pathetic']\n",
    "docs_words = [doc.split(' ') for doc in docs]\n",
    "docs_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaed20d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>-0.001072</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>-0.018606</td>\n",
       "      <td>-0.014234</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>0.017946</td>\n",
       "      <td>-0.010031</td>\n",
       "      <td>-0.007527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019207</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>-0.017519</td>\n",
       "      <td>-0.008784</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.015322</td>\n",
       "      <td>0.019229</td>\n",
       "      <td>0.009964</td>\n",
       "      <td>0.018466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>-0.016316</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>-0.008274</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>-0.013574</td>\n",
       "      <td>-0.007097</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>0.010121</td>\n",
       "      <td>-0.017835</td>\n",
       "      <td>-0.014083</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.012785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>-0.017239</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.014934</td>\n",
       "      <td>-0.012335</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>-0.012347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015796</td>\n",
       "      <td>-0.013979</td>\n",
       "      <td>-0.018312</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.003580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pathetic</th>\n",
       "      <td>0.015635</td>\n",
       "      <td>-0.019020</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.018022</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>-0.001423</td>\n",
       "      <td>0.015421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>-0.015763</td>\n",
       "      <td>-0.005434</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>-0.004783</td>\n",
       "      <td>-0.019020</td>\n",
       "      <td>0.009012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>-0.013625</td>\n",
       "      <td>-0.002751</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>-0.007347</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>-0.016634</td>\n",
       "      <td>0.012411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011188</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>-0.001795</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>-0.005400</td>\n",
       "      <td>-0.008734</td>\n",
       "      <td>-0.002064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>0.002874</td>\n",
       "      <td>-0.005292</td>\n",
       "      <td>-0.014148</td>\n",
       "      <td>-0.015611</td>\n",
       "      <td>-0.018244</td>\n",
       "      <td>-0.011870</td>\n",
       "      <td>-0.003695</td>\n",
       "      <td>-0.008648</td>\n",
       "      <td>-0.012921</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009019</td>\n",
       "      <td>0.011403</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>-0.008200</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.016426</td>\n",
       "      <td>-0.014038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>-0.016485</td>\n",
       "      <td>0.018599</td>\n",
       "      <td>-0.000395</td>\n",
       "      <td>-0.003935</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>-0.008191</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>0.013880</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>-0.015022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006860</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.012565</td>\n",
       "      <td>-0.005609</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>-0.004761</td>\n",
       "      <td>-0.006256</td>\n",
       "      <td>-0.004740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5   \\\n",
       "movie    -0.001072  0.000473  0.010207  0.018019 -0.018606 -0.014234   \n",
       "is       -0.016316  0.008992 -0.008274  0.001649  0.016997 -0.008924   \n",
       "this     -0.017239  0.007331  0.010380  0.011484  0.014934 -0.012335   \n",
       "pathetic  0.015635 -0.019020 -0.000411  0.006938 -0.001878  0.016764   \n",
       "was       0.000189  0.006155 -0.013625 -0.002751  0.015337  0.014693   \n",
       "awesome   0.002874 -0.005292 -0.014148 -0.015611 -0.018244 -0.011870   \n",
       "good     -0.016485  0.018599 -0.000395 -0.003935  0.009207 -0.008191   \n",
       "\n",
       "                6         7         8         9   ...        40        41  \\\n",
       "movie     0.012918  0.017946 -0.010031 -0.007527  ... -0.019207  0.010015   \n",
       "is        0.009035 -0.013574 -0.007097  0.018797  ...  0.003263  0.000380   \n",
       "this      0.002211  0.012095 -0.005680 -0.012347  ...  0.015796 -0.013979   \n",
       "pathetic  0.018022  0.013073 -0.001423  0.015421  ...  0.002175 -0.003152   \n",
       "was      -0.007347  0.005285 -0.016634  0.012411  ... -0.011188  0.003461   \n",
       "awesome  -0.003695 -0.008648 -0.012921 -0.007435  ... -0.009019  0.011403   \n",
       "good      0.005486  0.013880  0.012131 -0.015022  ...  0.006860  0.010332   \n",
       "\n",
       "                42        43        44        45        46        47  \\\n",
       "movie    -0.017519 -0.008784 -0.000070 -0.000592 -0.015322  0.019229   \n",
       "is        0.006947  0.000436  0.019238  0.010121 -0.017835 -0.014083   \n",
       "this     -0.018312 -0.000712 -0.006200  0.015789  0.011877 -0.003091   \n",
       "pathetic  0.004393 -0.015763 -0.005434  0.005326  0.010693 -0.004783   \n",
       "was      -0.001795  0.013587  0.007947  0.009059  0.002869 -0.005400   \n",
       "awesome   0.018360 -0.008200  0.015929  0.010751  0.011758  0.001025   \n",
       "good      0.012565 -0.005609  0.014645  0.005661  0.005742 -0.004761   \n",
       "\n",
       "                48        49  \n",
       "movie     0.009964  0.018466  \n",
       "is        0.001803  0.012785  \n",
       "this      0.003022  0.003580  \n",
       "pathetic -0.019020  0.009012  \n",
       "was      -0.008734 -0.002064  \n",
       "awesome   0.016426 -0.014038  \n",
       "good     -0.006256 -0.004740  \n",
       "\n",
       "[7 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimension of word vector representation\n",
    "embedding_dim = 50 \n",
    "# min_count is minimum frequence required for a word to be considered\n",
    "model = word2vec.Word2Vec(sentences=docs_words, vector_size=embedding_dim, min_count=1, window=2, sg=1)\n",
    "vocab = model.wv.index_to_key\n",
    "df_embedding_matrix = pd.DataFrame(model.wv[vocab], index=vocab)\n",
    "df_embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240ceded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie', 'is', 'this', 'pathetic', 'was', 'awesome', 'good']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26f82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b57309db",
   "metadata": {},
   "source": [
    "# Pretrained Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3748cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ZipInfo filename='GoogleNews-vectors-negative300/' filemode='drwxrwxr-x' external_attr=0x10>,\n",
       " <ZipInfo filename='glove.840B.300d/' filemode='drwxrwxr-x' external_attr=0x10>,\n",
       " <ZipInfo filename='paragram_300_sl999/' filemode='drwxr-xr-x' external_attr=0x10>,\n",
       " <ZipInfo filename='wiki-news-300d-1M/' filemode='drwxrwxr-x' external_attr=0x10>,\n",
       " <ZipInfo filename='glove.840B.300d/glove.840B.300d.txt' compress_type=deflate filemode='-rw-rw-r--' file_size=5646236541 compress_size=2178478737>,\n",
       " <ZipInfo filename='GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin' compress_type=deflate filemode='-rw-rw-r--' file_size=3644258522 compress_size=1746270195>,\n",
       " <ZipInfo filename='wiki-news-300d-1M/wiki-news-300d-1M.vec' compress_type=deflate filemode='-rw-r--r--' file_size=2259088777 compress_size=682384991>,\n",
       " <ZipInfo filename='paragram_300_sl999/README.txt' compress_type=deflate filemode='-rw-r--r--' file_size=731 compress_size=441>,\n",
       " <ZipInfo filename='paragram_300_sl999/paragram_300_sl999.txt' compress_type=deflate filemode='-rw-r-----' file_size=4555969303 compress_size=1788784124>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_path = 'data/quora-insincere-questions-classification/embeddings.zip'\n",
    "from zipfile import ZipFile\n",
    "zf = ZipFile(zip_path)\n",
    "zf.filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92fe41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c866875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "embeddings = KeyedVectors.load_word2vec_format(zf.open(embedding_file), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2abd881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d953550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings['computer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a1ebf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computers', 0.7979379892349243),\n",
       " ('laptop', 0.6640493869781494),\n",
       " ('laptop_computer', 0.6548868417739868),\n",
       " ('Computer', 0.6473335027694702),\n",
       " ('com_puter', 0.6082079410552979)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar('computer', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c03d1d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kidney_dialysis', 0.7938171029090881),\n",
       " ('hemodialysis', 0.7668044567108154),\n",
       " ('dialysis_treatments', 0.714596688747406),\n",
       " ('Dialysis', 0.6839954257011414),\n",
       " ('renal_dialysis', 0.6658204197883606)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar('dialysis', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02b1daaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('internal_bleeding', 0.6030535697937012),\n",
       " ('bronchopneumonia', 0.5957473516464233),\n",
       " ('bowel_obstruction', 0.5952029824256897),\n",
       " ('renal_failure', 0.5949323177337646),\n",
       " ('bowel_perforation', 0.5859941244125366)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar('peritonitis', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "317d2839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519), ('monarch', 0.6189674735069275)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.most_similar(positive=['king', 'woman'], negative=['man'], topn=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ed93b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('homemaker', 0.5627118945121765),\n",
       " ('housewife', 0.5105046629905701),\n",
       " ('graphic_designer', 0.505180299282074),\n",
       " ('schoolteacher', 0.497949481010437),\n",
       " ('businesswoman', 0.493489146232605)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negetive side of embeddings\n",
    "\n",
    "embeddings.most_similar(positive=['computer_programmer', 'woman'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec37928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a242afec",
   "metadata": {},
   "source": [
    "## Text Classification using pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b81db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891d2f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-17cb95938bd9>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  docs = data['question_text'].str.lower().str.replace('[^a-z\\s]', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1108909</th>\n",
       "      <td>d94bf3ddbbf06d1808b7</td>\n",
       "      <td>What is fundamentals of information technology?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225377</th>\n",
       "      <td>2c140d1fd368daa4a5ae</td>\n",
       "      <td>Is it possible to raise a family on what one m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919967</th>\n",
       "      <td>b447244d801fc617ddf3</td>\n",
       "      <td>Have you ever received a diagnosis of a medica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057794</th>\n",
       "      <td>cf45848e3bc65ed6e1f7</td>\n",
       "      <td>What is a good program to search and highlight...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097610</th>\n",
       "      <td>d71e829c329310797dff</td>\n",
       "      <td>How can I find out who made a specific friend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1108909  d94bf3ddbbf06d1808b7   \n",
       "225377   2c140d1fd368daa4a5ae   \n",
       "919967   b447244d801fc617ddf3   \n",
       "1057794  cf45848e3bc65ed6e1f7   \n",
       "1097610  d71e829c329310797dff   \n",
       "\n",
       "                                             question_text  target  \n",
       "1108909    What is fundamentals of information technology?       0  \n",
       "225377   Is it possible to raise a family on what one m...       0  \n",
       "919967   Have you ever received a diagnosis of a medica...       0  \n",
       "1057794  What is a good program to search and highlight...       0  \n",
       "1097610  How can I find out who made a specific friend ...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/quora-insincere-questions-classification/train.csv').sample(10000)\n",
    "docs = data['question_text'].str.lower().str.replace('[^a-z\\s]', '')\n",
    "docs = docs.apply(remove_stopwords)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fa0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52910e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_text, y_train, y_test = train_test_split(docs, data['target'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "190cebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16025adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique tokens: 13043\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab = list(tokenizer.word_index)\n",
    "print(f'Total number of unique tokens: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a1b605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5448, 5449, 3497, 51, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_validate_seq = tokenizer.texts_to_sequences(X_text)\n",
    "X_train_seq[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50f2593f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_size = []\n",
    "for doc in X_train_seq:\n",
    "    size = len(doc)\n",
    "    docs_size.append(size)\n",
    "    \n",
    "    \n",
    "pd.Series(docs_size).plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f86120ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  84, 1416,  663, ..., 1671,    0,    0],\n",
       "       [1672,  664,  193, ..., 1067,  840,  124],\n",
       "       [  17,  941,  299, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [2086,   81,    0, ...,    0,    0,    0],\n",
       "       [ 629,  506,  520, ...,    0,    0,    0],\n",
       "       [3710, 1802, 2411, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_doc_len = 10\n",
    "# max_doc_len = max(docs_size)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, padding='post', maxlen=max_doc_len)\n",
    "X_validate_padded = pad_sequences(X_validate_seq, padding='post', maxlen=max_doc_len)\n",
    "X_train_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d40021f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13043"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d823523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This +1 is added for 0 padding element\n",
    "vocab_size = len(vocab) + 1\n",
    "embedding_dim = 300\n",
    "words_not_available = []\n",
    "embedding_maxtrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, wid in tokenizer.word_index.items():\n",
    "    if word in embeddings:\n",
    "        embedding_maxtrix[wid] = embeddings[word]\n",
    "    else:\n",
    "        words_not_available.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eca1948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of words not available 15.970252242582228\n"
     ]
    }
   ],
   "source": [
    "print(f'Percent of words not available {len(words_not_available)/len(vocab)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6c69729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d6cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4480 - accuracy: 0.9291\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2925 - accuracy: 0.9377\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2360 - accuracy: 0.9378\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9380\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2126 - accuracy: 0.9380\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9382\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9382\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2092 - accuracy: 0.9381\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9385\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9385\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim,\n",
    "                          weights = [embedding_maxtrix],\n",
    "                          input_length=max_doc_len,\n",
    "                          trainable=False))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_padded, y_train, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85e8855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.9490\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_validate_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d27cb9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d888dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6878da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79132f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b89369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2090a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf07fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269a05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3941fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e539a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8790a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068c399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
