{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T04:12:14.405908Z",
     "iopub.status.busy": "2022-02-02T04:12:14.405100Z",
     "iopub.status.idle": "2022-02-02T04:12:19.510408Z",
     "shell.execute_reply": "2022-02-02T04:12:19.509812Z",
     "shell.execute_reply.started": "2022-02-02T04:12:14.405804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "from colorama import Fore\n",
    "from glob import glob\n",
    "import json\n",
    "from pprint import pprint\n",
    "import time\n",
    "import cv2\n",
    "from enum import Enum\n",
    "from IPython.display import display\n",
    "from pandas_profiling import ProfileReport\n",
    "from IPython.display import HTML, display\n",
    "import random\n",
    "import inspect\n",
    "\n",
    "# For Data preparation\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, VotingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T04:12:19.512079Z",
     "iopub.status.busy": "2022-02-02T04:12:19.511714Z",
     "iopub.status.idle": "2022-02-02T04:12:19.518798Z",
     "shell.execute_reply": "2022-02-02T04:12:19.517616Z",
     "shell.execute_reply.started": "2022-02-02T04:12:19.512048Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config(Enum):\n",
    "    '''\n",
    "    It basically contains all the path location and other stuffs\n",
    "    '''\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value\n",
    "\n",
    "    TRAIN_CSV = \"../input/wipro-challenge/train.csv\"\n",
    "    TEST_CSV = \"../input/wipro-challenge/test.csv\"\n",
    "    SAMPLE_CSV = \"../input/wipro-challenge/sample_submission.csv\"\n",
    "    FEATURES = [\n",
    "            'Year',\n",
    "            'Month',\n",
    "            'Day',\n",
    "            'Hour',\n",
    "            'Minute',\n",
    "            'Cloud Type',\n",
    "            'Dew Point',\n",
    "            'Temperature',\n",
    "            'Pressure',\n",
    "            'Relative Humidity',\n",
    "            'Solar Zenith Angle',\n",
    "            'Precipitable Water',\n",
    "            'Wind Direction',\n",
    "            'Wind Speed',\n",
    "            'Fill Flag'\n",
    "            ]\n",
    "    LABEL = [\n",
    "            'Clearsky DHI', \n",
    "            'Clearsky DNI', \n",
    "            'Clearsky GHI',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T04:38:25.403156Z",
     "iopub.status.busy": "2022-02-02T04:38:25.402856Z",
     "iopub.status.idle": "2022-02-02T04:38:25.439158Z",
     "shell.execute_reply": "2022-02-02T04:38:25.438550Z",
     "shell.execute_reply.started": "2022-02-02T04:38:25.403124Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotCorrelation(df: \"dataFrame\"):\n",
    "    \"\"\"\n",
    "    Helper function to plot correlation plot\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        go.Heatmap(\n",
    "            z=df.corr().values,\n",
    "            x=df.columns.values,\n",
    "            y=df.columns.values,\n",
    "            colorscale='Rainbow',\n",
    "            reversescale=False,\n",
    "            #                 text = True,\n",
    "            opacity=1.0)\n",
    "    ]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Pearson Correlation plot',\n",
    "        title_x=0.5,\n",
    "        xaxis=dict(ticks='', nticks=36),\n",
    "        yaxis=dict(ticks=''),\n",
    "        width=900, height=700)\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def plot_scatterMatrix(df: \"dataframe\", cols: list):\n",
    "    \"\"\"\n",
    "    Helper function to plot scatter matrix\n",
    "    \"\"\"\n",
    "    data_matrix = df.loc[:, cols]\n",
    "    data_matrix[\"index\"] = np.arange(1, len(data_matrix)+1)\n",
    "    # scatter matrix\n",
    "    fig = ff.create_scatterplotmatrix(data_matrix, diag='box', index='index', colormap='Portland',\n",
    "                                      colormap_type='cat',\n",
    "                                      height=700, width=700)\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "def create_folds(data, target=\"label\", regression=True, num_splits=5):\n",
    "    \"\"\"\n",
    "    Helper function to create folds\n",
    "    \"\"\"\n",
    "    data[\"kfold\"] = -1\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    kf = StratifiedKFold(n_splits=num_splits)\n",
    "\n",
    "    if regression:\n",
    "        # Applying Sturg's rule to calculate the no. of bins for target\n",
    "        num_bins = int(1 + np.log2(len(data)))\n",
    "\n",
    "        data.loc[:, \"bins\"] = pd.cut(data[target], bins=num_bins, labels=False)\n",
    "        for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n",
    "            data.loc[v_, 'kfold'] = f\n",
    "        data = data.drop([\"bins\"], axis=1)\n",
    "    else:\n",
    "        for f, (t_, v_) in enumerate(kf.split(X=data, y=data[target].values)):\n",
    "            data.loc[v_, 'kfold'] = f\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def rmse_score(y_label, y_preds):\n",
    "    \"\"\"\n",
    "    Gives RMSE score\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_label, y_preds))\n",
    "\n",
    "\n",
    "def trainRegModels(df: \"data_file\", useStandardization: bool, features: list, label: str, sortByRMSE = True):\n",
    "    \"\"\"\n",
    "    To automate the training of regression models. Considering\n",
    "        > RMSE\n",
    "        > R2 score\n",
    "    \"\"\"\n",
    "    regModels = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=2),\n",
    "        \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0, n_estimators=100),\n",
    "        \"LGBMRegressor\": LGBMRegressor(),\n",
    "        \"Ridge\": Ridge(alpha=1.0),\n",
    "        \"ElasticNet\": ElasticNet(random_state=0),\n",
    "        \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "        \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "        \"ExtraTreesRegressor\": ExtraTreesRegressor(n_jobs=-1),\n",
    "        \"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1),\n",
    "        \"XGBRegressor\": XGBRegressor(n_jobs=-1),\n",
    "        \"CatBoostRegressor\": CatBoostRegressor(iterations=900, depth=5, learning_rate=0.05, loss_function='RMSE'),\n",
    "    }\n",
    "\n",
    "    # Will return this as a data frame\n",
    "    summary = {\n",
    "        \"Model\": [],\n",
    "        \"Avg R2 Train Score\": [],\n",
    "        \"Avg R2 Val Score\": [],\n",
    "        \"Avg RSME Train Score\": [],\n",
    "        \"Avg RSME Val Score\": []\n",
    "    }\n",
    "\n",
    "    # Training\n",
    "    folds = 1 + max(df.kfold.values)\n",
    "    for idx in trange(len(regModels.keys()), desc=f\"Models are training, LABEL: {label}...\", bar_format=\"{l_bar}%s{bar:50}%s{r_bar}\" % (Fore.CYAN, Fore.RESET), position=0, leave=True):\n",
    "        name = list(regModels.keys())[idx]\n",
    "        model = regModels[name]\n",
    "\n",
    "        # Initializing all the scores to 0\n",
    "        r2_train = 0\n",
    "        r2_val = 0\n",
    "        rmse_train = 0\n",
    "        rmse_val = 0\n",
    "\n",
    "        # Running K-fold Cross-validation on every model\n",
    "        for fold in range(folds):\n",
    "            train_df = df.loc[df.kfold != fold].reset_index(drop=True)\n",
    "            val_df = df.loc[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "            train_X = train_df[features]\n",
    "            train_Y = train_df[label]\n",
    "            val_X = val_df[features]\n",
    "            val_Y = val_df[label]\n",
    "            \n",
    "            if useStandardization:\n",
    "                ss = StandardScaler()\n",
    "                ss.fit_transform(train_X)\n",
    "                ss.transform(val_X)\n",
    "                \n",
    "            cur_model = model\n",
    "            if name == 'CatBoostRegressor':\n",
    "                cur_model.fit(train_X, train_Y, verbose=False)\n",
    "            else:\n",
    "                cur_model.fit(train_X, train_Y)\n",
    "\n",
    "            Y_train_preds = model.predict(train_X)\n",
    "            Y_val_preds = model.predict(val_X)\n",
    "\n",
    "            # Collecting the scores\n",
    "            r2_train += r2_score(train_Y, Y_train_preds)\n",
    "            r2_val += r2_score(val_Y, Y_val_preds)\n",
    "\n",
    "            rmse_train += rmse_score(train_Y, Y_train_preds)\n",
    "            rmse_val += rmse_score(val_Y, Y_val_preds)\n",
    "\n",
    "        # Pushing the scores and the Model names\n",
    "        summary[\"Model\"].append(name)\n",
    "        summary[\"Avg R2 Train Score\"].append(r2_train/folds)\n",
    "        summary[\"Avg R2 Val Score\"].append(r2_val/folds)\n",
    "        summary[\"Avg RSME Train Score\"].append(rmse_train/folds)\n",
    "        summary[\"Avg RSME Val Score\"].append(rmse_val/folds)\n",
    "\n",
    "    # Finally returning the summary dictionary as a dataframe\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    if sortByRMSE:\n",
    "        summary_df = summary_df.sort_values([\"Avg RSME Val Score\", \"Avg R2 Val Score\"], ascending = True)\n",
    "    else:\n",
    "        summary_df = summary_df.sort_values([\"Avg R2 Val Score\", \"Avg RSME Val Score\", ], ascending = True)\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def train2Test(train_df: \"train dataframe\", test_df: \"test dataframe\", useStandardization: bool, model_name: str, features: list, label: str, submission_name = \"submission_df\"):\n",
    "    \"\"\"\n",
    "    Helper function to:\n",
    "    > Train the given Model\n",
    "    > Perform standardization in set to true\n",
    "    > Perform Inference on the test data\n",
    "    > Return the test data with the label\n",
    "    > Saves the test data in `Inference Results` folder\n",
    "    \n",
    "    \"\"\"\n",
    "    regModels = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=2),\n",
    "        \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0, n_estimators=100),\n",
    "        \"LGBMRegressor\": LGBMRegressor(),\n",
    "        \"Ridge\": Ridge(alpha=1.0),\n",
    "        \"ElasticNet\": ElasticNet(random_state=0),\n",
    "        \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "        \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "        \"ExtraTreesRegressor\": ExtraTreesRegressor(n_jobs=-1),\n",
    "        \"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1),\n",
    "        \"XGBRegressor\": XGBRegressor(n_jobs=-1),\n",
    "        \"CatBoostRegressor\": CatBoostRegressor(iterations=900, depth=5, learning_rate=0.05, loss_function='RMSE'),\n",
    "    }\n",
    "    \n",
    "    if model_name not in regModels:\n",
    "        print(\"[INFO] Please select among the available models are the follows: \")\n",
    "        pprint(list(regModels.keys()))\n",
    "        return\n",
    "    else:\n",
    "        model = regModels[model_name]\n",
    "        train_X = train_df[features]\n",
    "        train_Y = train_df[label]\n",
    "        test_features = test_df[features]\n",
    "        if useStandardization:\n",
    "            ss = StandardScaler()\n",
    "            ss.fit_transform(train_X)\n",
    "            ss.transform(test_features)\n",
    "        \n",
    "        model.fit(train_X, train_Y)\n",
    "        \n",
    "        #  Performing Inference\n",
    "        test_preds = model.predict(test_features)\n",
    "        test_df[label] = list(test_preds)\n",
    "        \n",
    "        # Saving the test preds\n",
    "        if not os.path.exists(\"./Inference Results\"):\n",
    "            os.mkdir(\"./Inference Results\")\n",
    "        \n",
    "        test_df.to_csv(f\"./Inference Results/{submission_name}.csv\", index = False)\n",
    "        return test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T04:12:50.455759Z",
     "iopub.status.busy": "2022-02-02T04:12:50.455475Z",
     "iopub.status.idle": "2022-02-02T04:12:51.110263Z",
     "shell.execute_reply": "2022-02-02T04:12:51.109419Z",
     "shell.execute_reply.started": "2022-02-02T04:12:50.455731Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(Config.TRAIN_CSV.value)[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Cloud Type', 'Dew Point',\n",
    "       'Temperature', 'Pressure', 'Relative Humidity', 'Solar Zenith Angle',\n",
    "       'Precipitable Water', 'Wind Direction', 'Wind Speed', 'Fill Flag','Clearsky DNI', 'Clearsky GHI', 'Clearsky DHI']]\n",
    "test_df = pd.read_csv(Config.TEST_CSV.value)\n",
    "sample_df = pd.read_csv(Config.SAMPLE_CSV.value)\n",
    "\n",
    "print(len(data_df), len(test_df), len(sample_df))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T04:12:51.112038Z",
     "iopub.status.busy": "2022-02-02T04:12:51.111728Z",
     "iopub.status.idle": "2022-02-02T04:12:51.120789Z",
     "shell.execute_reply": "2022-02-02T04:12:51.120043Z",
     "shell.execute_reply.started": "2022-02-02T04:12:51.112008Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T04:44:49.550185Z",
     "iopub.status.busy": "2022-02-02T04:44:49.549400Z",
     "iopub.status.idle": "2022-02-02T04:45:17.737316Z",
     "shell.execute_reply": "2022-02-02T04:45:17.736318Z",
     "shell.execute_reply.started": "2022-02-02T04:44:49.550138Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for label in Config.LABEL.value:\n",
    "    tmp_df = train2Test(train_df = data_df,\n",
    "                        test_df = test_df,\n",
    "                        useStandardization = True,\n",
    "                        model_name = 'XGBRegressor',\n",
    "                        features = Config.FEATURES.value,\n",
    "                        label = label,\n",
    "                        submission_name = f\"{label}_submission_df.csv\"\n",
    "                      )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T04:47:41.516688Z",
     "iopub.status.busy": "2022-02-02T04:47:41.516166Z",
     "iopub.status.idle": "2022-02-02T04:47:41.611631Z",
     "shell.execute_reply": "2022-02-02T04:47:41.611131Z",
     "shell.execute_reply.started": "2022-02-02T04:47:41.516658Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = test_df[Config.LABEL.value]\n",
    "submission_df.to_csv('submission_df.csv', index = False)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
